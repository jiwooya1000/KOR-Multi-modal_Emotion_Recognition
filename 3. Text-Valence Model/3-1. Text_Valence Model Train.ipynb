{"cells":[{"cell_type":"markdown","metadata":{"id":"cw9r82IKh0gL"},"source":["# **모델 구현 (ing)**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38213,"status":"ok","timestamp":1651763761315,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"VJw0hfYvtlaO","outputId":"06b4e785-5ddd-44a2-86ea-c5be69f8ab65"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.9.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.28)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.8)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n","Collecting transformers==3.0.2\n","  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.0.53)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.64.0)\n","Collecting tokenizers==0.8.1.rc1\n","  Using cached tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.6)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.6.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.12.1\n","    Uninstalling tokenizers-0.12.1:\n","      Successfully uninstalled tokenizers-0.12.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.18.0\n","    Uninstalling transformers-4.18.0:\n","      Successfully uninstalled transformers-4.18.0\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","kobert 0.2.3 requires transformers>=4.8.1, but you have transformers 3.0.2 which is incompatible.\u001b[0m\n","Successfully installed tokenizers-0.8.1rc1 transformers-3.0.2\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-svwln5kx\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-svwln5kx\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.22.7)\n","Requirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n","Requirement already satisfied: mxnet>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.9.0)\n","Requirement already satisfied: onnxruntime==1.8.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.8.0)\n","Requirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.11.0+cu113)\n","Collecting transformers>=4.8.1\n","  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.17.3)\n","Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.21.6)\n","Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.28)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.23.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (0.8.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.25.11)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.3) (4.2.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (2019.12.20)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.11.3)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (6.0)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.53)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.5.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.64.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.8)\n","Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.0.0)\n","Requirement already satisfied: botocore<1.26.0,>=1.25.7 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.25.7)\n","Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (0.5.2)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.7->boto3->kobert==0.2.3) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.26.0,>=1.25.7->boto3->kobert==0.2.3) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.3) (3.8.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (1.1.0)\n","Installing collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.8.1rc1\n","    Uninstalling tokenizers-0.8.1rc1:\n","      Successfully uninstalled tokenizers-0.8.1rc1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 3.0.2\n","    Uninstalling transformers-3.0.2:\n","      Successfully uninstalled transformers-3.0.2\n","Successfully installed tokenizers-0.12.1 transformers-4.18.0\n","Collecting kobert_tokenizer\n","  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-brdq8yr9/kobert-tokenizer_79c5d856512948479311d9e131a537fe\n","  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-brdq8yr9/kobert-tokenizer_79c5d856512948479311d9e131a537fe\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.8.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (0.3.2)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n"]}],"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3.0.2\n","!pip install torch\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n","!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n","!pip install torchmetrics"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":6932,"status":"ok","timestamp":1651763768243,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"YVFpzmG7tmrx"},"outputs":[],"source":["import torch\n","import time\n","import os\n","import pandas as pd\n","import numpy as np\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import gluonnlp as nlp\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from kobert_tokenizer import KoBERTTokenizer\n","from transformers import BertTokenizer, BertModel\n","from kobert import get_pytorch_kobert_model\n","from sklearn.metrics import f1_score"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1844,"status":"ok","timestamp":1651763770082,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"DNKr8LNNtow5","outputId":"d3489083-0c6b-4d4c-c956-fd585ef34403"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# Drive Mount\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","directory = \"주분\"\n","path = \"/content/gdrive/My Drive/\" + directory\n","os.chdir(path)"]},{"cell_type":"markdown","metadata":{"id":"qxoxVTFuh47x"},"source":["## **1. 데이터로더 준비**"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10311,"status":"ok","timestamp":1651763780391,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"etx3DeXatqRH","outputId":"cf97f436-3315-433f-9e9f-085be4f604a4"},"outputs":[{"name":"stderr","output_type":"stream","text":["The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n","The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n","The class this function is called from is 'KoBERTTokenizer'.\n"]},{"name":"stdout","output_type":"stream","text":["using cached model. /content/gdrive/My Drive/주분/.cache/kobert_v1.zip\n","using cached model. /content/gdrive/MyDrive/주분/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}],"source":["# KoBERT tokenizer 및 모델 불러오기\n","\n","tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n","model, vocab = get_pytorch_kobert_model()"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1651763780392,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"ZXYorh8BtzMK"},"outputs":[],"source":["# Custom Dataset 불러오기\n","\n","from dataloader import *"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39402,"status":"ok","timestamp":1651763819784,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"wHOiM119tryB","outputId":"76244398-3bb7-4be8-b36a-785e30e42cf7"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 10043/10043 [00:09<00:00, 1108.49it/s]\n"]}],"source":["# Custom Dataset 객체 생성(Train Set)\n","\n","dataset_train = KEMDset(file='train_aft_aug_kobert.pickle', tokenizer=tokenizer, balance=False, shuffle=True)"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1651763819785,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"LzRONwqqt2HN"},"outputs":[],"source":["# DataLoader 정의\n","\n","dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=64,\n","                                               shuffle=False, drop_last=True)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3895,"status":"ok","timestamp":1651763824121,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"AktAmdsfCvSo","outputId":"8142f042-33ae-4aba-8551-dd1bcbd3848e"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1018/1018 [00:00<00:00, 1153.41it/s]\n"]}],"source":["# Custom Dataset 객체 생성(Valid Set)\n","\n","dataset_valid = KEMDset(file='valid_tokenized.pickle', tokenizer=tokenizer, balance=False, shuffle=True)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1651763824121,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"3Cjitup1C42t"},"outputs":[],"source":["# DataLoader 정의\n","\n","dataloader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=64,\n","                                               shuffle=False, drop_last=True)"]},{"cell_type":"markdown","metadata":{"id":"Fjht-T0-vpLz"},"source":["## **2. 모델**"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651763824584,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"qnkUCsVWwfTw"},"outputs":[],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651763824585,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"8MplSgnEvqot"},"outputs":[],"source":["# 모델 정의해놓은 모듈 불러오기\n","\n","from text_model import *\n","from EarlyStopping import *"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651763824585,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"BX04RyPAt3yV"},"outputs":[],"source":["import importlib\n","import text_model\n","importlib.reload(text_model)\n","from text_model import *"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11900,"status":"ok","timestamp":1651763836480,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"-gbnCx-Uvqxu","outputId":"2d5d3866-4fe0-4fb6-a7c5-bb3f5ed828b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["using cached model. /content/gdrive/MyDrive/주분/.cache/kobert_v1.zip\n","using cached model. /content/gdrive/MyDrive/주분/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"]}],"source":["# 모델 객체 생성\n","\n","model = TextRegressor(n_layers=5).to(device)"]},{"cell_type":"markdown","metadata":{"id":"hNJvQtYv69o4"},"source":["## **3. 학습**"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1651763836481,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"Uki4KcnK7CcA"},"outputs":[],"source":["# 하이퍼 파라미터 설정\n","\n","learning_rate = 2e-5\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.8)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":749142,"status":"ok","timestamp":1651764585611,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"bp4acrw5OePS","outputId":"0d025330-8cec-4ed7-ea82-8acc81f0c96e"},"outputs":[],"source":["# 모델 학습\n","\n","epochs=30 \n","train_losses = []\n","valid_losses = []\n","\n","start_time = time.time()\n","es = EarlyStopping(patience=8, path='text_valence.pt')\n","\n","for epoch in range(epochs):\n","    \n","    #########\n","    # Train #\n","    #########\n","    model.train()\n","    train_loss = 0\n","    \n","    for i, dict in enumerate(dataloader_train):\n","        input_ids = dict['input_ids'].to(device=device, dtype=torch.int32)\n","        token_type_ids = dict['token_type_ids'].to(device=device, dtype=torch.int32)\n","        attention_mask = dict['attention_mask'].to(device=device, dtype=torch.int32)\n","        targets = dict['valence'].to(device=device, dtype=torch.float32).unsqueeze(1)\n","\n","        scores, features = model(input_ids, token_type_ids, attention_mask)\n","    \n","        loss_fn = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n","        loss = torch.sqrt(loss_fn(scores, targets))\n","\n","        train_loss += loss\n","        \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    scheduler.step()\n","        \n","    ##############\n","    # Validation #\n","    ##############\n","    model.eval()\n","    valid_loss = 0\n","\n","    with torch.no_grad():\n","        for i, dict in enumerate(dataloader_valid):\n","            input_ids = dict['input_ids'].to(device=device, dtype=torch.int32)\n","            token_type_ids = dict['token_type_ids'].to(device=device, dtype=torch.int32)\n","            attention_mask = dict['attention_mask'].to(device=device, dtype=torch.int32)\n","            targets = dict['valence'].to(device=device, dtype=torch.float32).unsqueeze(1)\n","  \n","            scores, features = model(input_ids, token_type_ids, attention_mask)\n","            _, preds = scores.max(dim=1)\n","\n","            valid_loss += torch.sqrt(loss_fn(scores, targets))\n","\n","    #######\n","    # Log #\n","    #######\n","    train_losses.append(train_loss.detach().cpu().numpy() / len(dataloader_train))\n","    valid_losses.append(valid_loss.detach().cpu().numpy() / len(dataloader_valid))\n","\n","    elapsed_time = time.time() - start_time\n","        \n","    print(f\"[{time.strftime('%H:%M:%S', time.gmtime(elapsed_time))}] Epoch {epoch+1:2d} \\\n","    >>> Train RMSE Loss: {train_losses[-1]:6.4f} \\\n","    >>> Valid RMSE Loss: {valid_losses[-1]:6.4f} \")\n","    \n","    es(valid_losses[-1], model)\n","\n","    if es.early_stop:\n","        print('Early Stopping Activated!')\n","        break\n","\n","# torch.save(model.state_dict(), 'text_valence.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"elapsed":507,"status":"ok","timestamp":1651764586113,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"BdGatbhXUpMJ","outputId":"76a5324a-ea63-4fbc-b4c8-544f8afc200a"},"outputs":[],"source":["# 시각화\n","\n","plt.figure(figsize=(6,5))\n","\n","plt.plot(train_losses)\n","plt.plot(valid_losses)\n","plt.title('RMSE Loss')\n","plt.legend(['Train','Valid'])\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1651764586114,"user":{"displayName":"홍지우","userId":"09687386104869736535"},"user_tz":-540},"id":"48-6d8u8NzgS"},"outputs":[],"source":["import csv\n","\n","with open('[Text]n_layers=5.csv', 'w', newline='') as f: \n","    writer = csv.writer(f) \n","    writer.writerow(train_losses)\n","    writer.writerow(valid_losses)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyPtkXus/GKKKQBNYA1KeQCK","collapsed_sections":[],"machine_shape":"hm","name":"싱글모달_모델학습(텍스트).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}

{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jiwooya1000/KOR-Multimodal-Emotion-Recognition/blob/main/3-1.%20Text_Valence_Model_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cw9r82IKh0gL"
      },
      "source": [
        "# **텍스트 Valence 예측 모델 학습**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJw0hfYvtlaO",
        "outputId": "10d41eb1-cc2a-4c94-ce30-1b8c11b958a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.3.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.28)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.8)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n",
            "Collecting transformers==3.0.2\n",
            "  Using cached transformers-3.0.2-py3-none-any.whl (769 kB)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.0.53)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (3.6.0)\n",
            "Collecting tokenizers==0.8.1.rc1\n",
            "  Using cached tokenizers-0.8.1rc1-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (0.1.96)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.0.2) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.0.2) (3.0.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.0.2) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.0.2) (1.1.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.12.1\n",
            "    Uninstalling tokenizers-0.12.1:\n",
            "      Successfully uninstalled tokenizers-0.12.1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.18.0\n",
            "    Uninstalling transformers-4.18.0:\n",
            "      Successfully uninstalled transformers-4.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kobert 0.2.3 requires transformers>=4.8.1, but you have transformers 3.0.2 which is incompatible.\u001b[0m\n",
            "Successfully installed tokenizers-0.8.1rc1 transformers-3.0.2\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.2.0)\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-pldsf4ea\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-pldsf4ea\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.22.8)\n",
            "Requirement already satisfied: gluonnlp>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.10.0)\n",
            "Requirement already satisfied: mxnet>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.9.0)\n",
            "Requirement already satisfied: onnxruntime==1.8.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.8.0)\n",
            "Requirement already satisfied: sentencepiece>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (0.1.96)\n",
            "Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from kobert==0.2.3) (1.11.0+cu113)\n",
            "Collecting transformers>=4.8.1\n",
            "  Using cached transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (2.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnxruntime==1.8.0->kobert==0.2.3) (1.21.6)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (0.29.28)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp>=0.6.0->kobert==0.2.3) (21.3)\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (2.23.0)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet>=1.4.0->kobert==0.2.3) (0.8.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet>=1.4.0->kobert==0.2.3) (1.25.11)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->kobert==0.2.3) (4.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (3.6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.5.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Using cached tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (2019.12.20)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers>=4.8.1->kobert==0.2.3) (0.0.53)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp>=0.6.0->kobert==0.2.3) (3.0.8)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.0.0)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.26.0,>=1.25.8 in /usr/local/lib/python3.7/dist-packages (from boto3->kobert==0.2.3) (1.25.8)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.26.0,>=1.25.8->boto3->kobert==0.2.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.26.0,>=1.25.8->boto3->kobert==0.2.3) (1.15.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers>=4.8.1->kobert==0.2.3) (3.8.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.8.1->kobert==0.2.3) (7.1.2)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.8.1rc1\n",
            "    Uninstalling tokenizers-0.8.1rc1:\n",
            "      Successfully uninstalled tokenizers-0.8.1rc1\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 3.0.2\n",
            "    Uninstalling transformers-3.0.2:\n",
            "      Successfully uninstalled transformers-3.0.2\n",
            "Successfully installed tokenizers-0.12.1 transformers-4.18.0\n",
            "Collecting kobert_tokenizer\n",
            "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-59iy74ts/kobert-tokenizer_97100b45192248ef8157454d8d21f669\n",
            "  Running command git clone -q https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-59iy74ts/kobert-tokenizer_97100b45192248ef8157454d8d21f669\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.11.0+cu113)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: pyDeprecate==0.3.* in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (0.3.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (4.2.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.8)\n"
          ]
        }
      ],
      "source": [
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3.0.2\n",
        "!pip install torch\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
        "!pip install 'git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf'\n",
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVFpzmG7tmrx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import gluonnlp as nlp\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "from kobert_tokenizer import KoBERTTokenizer\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from kobert import get_pytorch_kobert_model\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNKr8LNNtow5",
        "outputId": "a1cb2a26-a23d-4db6-b822-6f25820d1b47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Drive Mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# Directory 변경\n",
        "directory = \"주분\"\n",
        "path = \"/content/gdrive/My Drive/\" + directory\n",
        "os.chdir(path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxoxVTFuh47x"
      },
      "source": [
        "## **1. 데이터로더 준비**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etx3DeXatqRH",
        "outputId": "c4a2c18b-c93d-41e2-8696-3bdfffcac5ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
            "The class this function is called from is 'KoBERTTokenizer'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/My Drive/주분/.cache/kobert_v1.zip\n",
            "using cached model. /content/gdrive/MyDrive/주분/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "# KoBERT tokenizer 및 모델 불러오기\n",
        "\n",
        "tokenizer = KoBERTTokenizer.from_pretrained('skt/kobert-base-v1')\n",
        "model, vocab = get_pytorch_kobert_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZXYorh8BtzMK"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset 불러오기\n",
        "\n",
        "from dataloader import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wHOiM119tryB",
        "outputId": "ccd22c3e-50a5-4deb-b949-2569c080c514"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10043/10043 [00:08<00:00, 1154.55it/s]\n"
          ]
        }
      ],
      "source": [
        "# Custom Dataset 객체 생성(Train Set)\n",
        "\n",
        "dataset_train = KEMDset(file='train_aft_aug_kobert.pickle', tokenizer=tokenizer, balance=False, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzRONwqqt2HN"
      },
      "outputs": [],
      "source": [
        "# DataLoader 정의\n",
        "\n",
        "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=16,\n",
        "                                               shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AktAmdsfCvSo",
        "outputId": "1f272e29-d323-45df-d5ba-1fafffa8be96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1018/1018 [00:00<00:00, 1282.40it/s]\n"
          ]
        }
      ],
      "source": [
        "# Custom Dataset 객체 생성(Valid Set)\n",
        "\n",
        "dataset_valid = KEMDset(file='valid_tokenized.pickle', tokenizer=tokenizer, balance=False, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Cjitup1C42t"
      },
      "outputs": [],
      "source": [
        "# DataLoader 정의\n",
        "\n",
        "dataloader_valid = torch.utils.data.DataLoader(dataset_valid, batch_size=16,\n",
        "                                               shuffle=False, drop_last=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fjht-T0-vpLz"
      },
      "source": [
        "## **2. 모델**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnkUCsVWwfTw"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8MplSgnEvqot"
      },
      "outputs": [],
      "source": [
        "# 모델 정의해놓은 모듈 불러오기\n",
        "\n",
        "from text_model import *\n",
        "from EarlyStopping import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BX04RyPAt3yV"
      },
      "outputs": [],
      "source": [
        "import importlib\n",
        "import text_model\n",
        "importlib.reload(text_model)\n",
        "from text_model import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gbnCx-Uvqxu",
        "outputId": "a73c21d9-2a36-438c-ddbb-3daee8d3d5d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "using cached model. /content/gdrive/MyDrive/주분/.cache/kobert_v1.zip\n",
            "using cached model. /content/gdrive/MyDrive/주분/.cache/kobert_news_wiki_ko_cased-1087f8699e.spiece\n"
          ]
        }
      ],
      "source": [
        "# 모델 객체 생성\n",
        "\n",
        "model = TextRegressor(n_layers=5).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNJvQtYv69o4"
      },
      "source": [
        "## **3. 학습**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uki4KcnK7CcA"
      },
      "outputs": [],
      "source": [
        "# 하이퍼 파라미터 설정\n",
        "\n",
        "learning_rate = 2e-5\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.6) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bp4acrw5OePS",
        "outputId": "6097c4d2-9278-44f0-baa8-037eebff43ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00:44] Epoch  1     >>> Train RMSE Loss: 0.6819     >>> Valid RMSE Loss: 0.4670 \n",
            "[00:01:30] Epoch  2     >>> Train RMSE Loss: 0.4585     >>> Valid RMSE Loss: 0.4327 \n",
            "[00:02:16] Epoch  3     >>> Train RMSE Loss: 0.4328     >>> Valid RMSE Loss: 0.4280 \n",
            "[00:03:01] Epoch  4     >>> Train RMSE Loss: 0.4193     >>> Valid RMSE Loss: 0.4280 \n",
            "[00:03:47] Epoch  5     >>> Train RMSE Loss: 0.4135     >>> Valid RMSE Loss: 0.4299 \n",
            "EarlyStopping counter: 1 out of 8\n",
            "[00:04:31] Epoch  6     >>> Train RMSE Loss: 0.4065     >>> Valid RMSE Loss: 0.4284 \n",
            "EarlyStopping counter: 2 out of 8\n",
            "[00:05:15] Epoch  7     >>> Train RMSE Loss: 0.4030     >>> Valid RMSE Loss: 0.4264 \n",
            "[00:06:01] Epoch  8     >>> Train RMSE Loss: 0.4003     >>> Valid RMSE Loss: 0.4254 \n",
            "[00:06:46] Epoch  9     >>> Train RMSE Loss: 0.4002     >>> Valid RMSE Loss: 0.4252 \n",
            "[00:07:32] Epoch 10     >>> Train RMSE Loss: 0.3986     >>> Valid RMSE Loss: 0.4254 \n",
            "EarlyStopping counter: 1 out of 8\n",
            "[00:08:16] Epoch 11     >>> Train RMSE Loss: 0.3981     >>> Valid RMSE Loss: 0.4252 \n",
            "EarlyStopping counter: 2 out of 8\n",
            "[00:09:00] Epoch 12     >>> Train RMSE Loss: 0.3985     >>> Valid RMSE Loss: 0.4252 \n",
            "EarlyStopping counter: 3 out of 8\n",
            "[00:09:43] Epoch 13     >>> Train RMSE Loss: 0.3972     >>> Valid RMSE Loss: 0.4252 \n",
            "EarlyStopping counter: 4 out of 8\n",
            "[00:10:27] Epoch 14     >>> Train RMSE Loss: 0.3975     >>> Valid RMSE Loss: 0.4253 \n",
            "EarlyStopping counter: 5 out of 8\n",
            "[00:11:11] Epoch 15     >>> Train RMSE Loss: 0.3974     >>> Valid RMSE Loss: 0.4251 \n",
            "[00:11:57] Epoch 16     >>> Train RMSE Loss: 0.3975     >>> Valid RMSE Loss: 0.4251 \n",
            "[00:12:43] Epoch 17     >>> Train RMSE Loss: 0.3974     >>> Valid RMSE Loss: 0.4250 \n",
            "[00:13:29] Epoch 18     >>> Train RMSE Loss: 0.3978     >>> Valid RMSE Loss: 0.4250 \n",
            "[00:14:15] Epoch 19     >>> Train RMSE Loss: 0.3968     >>> Valid RMSE Loss: 0.4249 \n",
            "[00:15:00] Epoch 20     >>> Train RMSE Loss: 0.3970     >>> Valid RMSE Loss: 0.4249 \n",
            "EarlyStopping counter: 1 out of 8\n",
            "[00:15:44] Epoch 21     >>> Train RMSE Loss: 0.3973     >>> Valid RMSE Loss: 0.4249 \n",
            "[00:16:30] Epoch 22     >>> Train RMSE Loss: 0.3971     >>> Valid RMSE Loss: 0.4250 \n",
            "EarlyStopping counter: 1 out of 8\n",
            "[00:17:14] Epoch 23     >>> Train RMSE Loss: 0.3964     >>> Valid RMSE Loss: 0.4251 \n",
            "EarlyStopping counter: 2 out of 8\n",
            "[00:17:58] Epoch 24     >>> Train RMSE Loss: 0.3975     >>> Valid RMSE Loss: 0.4250 \n",
            "EarlyStopping counter: 3 out of 8\n",
            "[00:18:42] Epoch 25     >>> Train RMSE Loss: 0.3967     >>> Valid RMSE Loss: 0.4248 \n",
            "[00:19:27] Epoch 26     >>> Train RMSE Loss: 0.3972     >>> Valid RMSE Loss: 0.4249 \n",
            "EarlyStopping counter: 1 out of 8\n",
            "[00:20:11] Epoch 27     >>> Train RMSE Loss: 0.3969     >>> Valid RMSE Loss: 0.4249 \n",
            "EarlyStopping counter: 2 out of 8\n",
            "[00:20:55] Epoch 28     >>> Train RMSE Loss: 0.3976     >>> Valid RMSE Loss: 0.4251 \n",
            "EarlyStopping counter: 3 out of 8\n",
            "[00:21:39] Epoch 29     >>> Train RMSE Loss: 0.3973     >>> Valid RMSE Loss: 0.4248 \n",
            "EarlyStopping counter: 4 out of 8\n",
            "[00:22:23] Epoch 30     >>> Train RMSE Loss: 0.3973     >>> Valid RMSE Loss: 0.4250 \n",
            "EarlyStopping counter: 5 out of 8\n"
          ]
        }
      ],
      "source": [
        "# 모델 학습\n",
        "\n",
        "epochs=30\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "start_time = time.time()\n",
        "es = EarlyStopping(patience=8, path='text_valence.pt')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    #########\n",
        "    # Train #\n",
        "    #########\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    \n",
        "    for i, dict in enumerate(dataloader_train):\n",
        "        input_ids = dict['input_ids'].to(device=device, dtype=torch.int32)\n",
        "        token_type_ids = dict['token_type_ids'].to(device=device, dtype=torch.int32)\n",
        "        attention_mask = dict['attention_mask'].to(device=device, dtype=torch.int32)\n",
        "        targets = dict['valence'].to(device=device, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "        scores, features = model(input_ids, token_type_ids, attention_mask)\n",
        "        \n",
        "        # 가중치 쓰려면 (weight=loss_weight)\n",
        "        loss_fn = nn.MSELoss(size_average=None, reduce=None, reduction='mean')\n",
        "        loss = torch.sqrt(loss_fn(scores, targets))\n",
        "\n",
        "        train_loss += loss\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    scheduler.step()\n",
        "        \n",
        "    ##############\n",
        "    # Validation #\n",
        "    ##############\n",
        "    model.eval()\n",
        "    valid_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, dict in enumerate(dataloader_valid):\n",
        "            input_ids = dict['input_ids'].to(device=device, dtype=torch.int32)\n",
        "            token_type_ids = dict['token_type_ids'].to(device=device, dtype=torch.int32)\n",
        "            attention_mask = dict['attention_mask'].to(device=device, dtype=torch.int32)\n",
        "            targets = dict['valence'].to(device=device, dtype=torch.float32).unsqueeze(1)\n",
        "  \n",
        "            scores, features = model(input_ids, token_type_ids, attention_mask)\n",
        "            _, preds = scores.max(dim=1)\n",
        "\n",
        "            valid_loss += torch.sqrt(loss_fn(scores, targets))\n",
        "\n",
        "    #######\n",
        "    # Log #\n",
        "    #######\n",
        "    train_losses.append(train_loss.detach().cpu().numpy() / len(dataloader_train))\n",
        "    valid_losses.append(valid_loss.detach().cpu().numpy() / len(dataloader_valid))\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "        \n",
        "    print(f\"[{time.strftime('%H:%M:%S', time.gmtime(elapsed_time))}] Epoch {epoch+1:2d} \\\n",
        "    >>> Train RMSE Loss: {train_losses[-1]:6.4f} \\\n",
        "    >>> Valid RMSE Loss: {valid_losses[-1]:6.4f} \")\n",
        "    \n",
        "    es(valid_losses[-1], model)\n",
        "\n",
        "    if es.early_stop:\n",
        "        print('Early Stopping Activated!')\n",
        "        break\n",
        "\n",
        "# torch.save(model.state_dict(), 'text_valence.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "BdGatbhXUpMJ",
        "outputId": "55daeddf-a2b4-4fa0-ab0d-634ffe7d41ba"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# 시각화\n",
        "\n",
        "plt.figure(figsize=(6,5))\n",
        "\n",
        "plt.plot(train_losses)\n",
        "plt.plot(valid_losses)\n",
        "plt.title('RMSE Loss')\n",
        "plt.legend(['Train','Valid'])\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48-6d8u8NzgS"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "\n",
        "with open('[Text]n_layers=5.csv', 'w', newline='') as f: \n",
        "    writer = csv.writer(f) \n",
        "    writer.writerow(train_losses)\n",
        "    writer.writerow(valid_losses)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "3-1. Text_Valence_Model_Train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMVByZc8hRUhVMABLrKMsJd",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}